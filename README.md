# Capstone Project: Machine Learning Engineer Nano Degree
## Detecting Fake Twitter Followers

[Full Project Report](https://github.com/mchisvo/ML_Engineer_Capstone_Project/blob/main/Report/Capstone_Project.pdf)

[Notebooks](https://github.com/mchisvo/ML_Engineer_Capstone_Project/tree/main/Capstone-Project)


### Project Description
This Capstone project focused on the popular micro-blogging platform Twitter and deployed a Machine Learning (ML) model using a Sagemaker endpoint  to discern fake followers from real humans. This information is important for business as paying for sponsored tweets to bots is a waste of money and important to the user as a large follower count could be used to persuade others of one's legitimacy (“clout”). We, the user, the main product social media platforms sell need tools to help us gauge our digital interactions.

*Keywords* - machine learning, social media, fake follower, bots, Twitter

#### Dataset
The dataset for this project consisted of a subset of data from the [Cresci-2017](https://botometer.osome.iu.edu/bot-repository/datasets.html) dataset, a collection of  genuine users (human) , fake followers, social spambots and traditional spam bots in .csv format. The subsets described below were used in training, validating and testing our model.

Dataset name | Description | Size | Target
------------ | ------------- |------------- | -------------
fake_followers.csv | A collection of fake accounts bought from three different providers in April 2013 - fastfollowerz.com, intertwitter.com, and twittertechnology.com | 3,351 | 1
genuine_accounts.csv | A random sample of human accounts generated by contacting users with a simple question in natural language, verified by a human. | 3,474 | 0


### Results
During this study, we were able to train and deploy a [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) (RF) using AWS SageMakers Machine Learning infrastructure achieving an accuracy score (correct predictions/total predictions) of __98.90%__

Such high accuracy scores suggest the two classes used in training and testing are easily separable, a phenomenon we seldom see in practice. High test accuracy suggests our model is not overfitting to the training data.

The high accuracy scores suggest this is an easy problem to solve using a binary classifier, however, the age of the Cresci-2017 dataset, constructed in 2013, could be the Achilles heel of this model were we to begin searching for fake followers in the current day. In 2022 fake followers still exist where a brief google search will bring you companies such as [Boost Likes](https://boostlikes.co/) offering 1000 “real” followers for £16.99, delivered within 24 hours of signing up. Social media companies such as Twitter are well aware of the presence of bots on their networks and as detection methods improve so do bots.

### Run

Run [Jupyter Notebooks](https://github.com/mchisvo/ML_Engineer_Capstone_Project/tree/main/Capstone-Project) in sequential order:

1\. 1_Data_Cleaning_&_Feature_Engineering.ipynb

2\. 2_EDA_&_Feature_Selection_Model_Selection.ipynb

3\. 3_Model_Training_Deployment.ipynb

#### Dependencies
- [numpy](https://numpy.org/)
- [pandas](https://pandas.pydata.org/)
- [scikit-learn](https://scikit-learn.org/stable/)
- [sagemaker](https://sagemaker.readthedocs.io/en/stable/overview.html)
- [borutapy](https://github.com/scikit-learn-contrib/boruta_py)

See requirements.txt for full list of python libraries
